<!DOCTYPE html>
<HTML>
<BODY>
<STYLE>
	h1 {
		font-size:200%;
	}
	table th,tr,td {
		border-collapse: collapse; /* share common border between cells */
		padding: 4px; /* padding within cells */
		table-layout : fixed
	}
	table th {
	background-color:lightsteelblue
	}
	/* Tooltip container */
		.tooltip {
		position: relative;
		display: inline-block;
	}
	/* Tooltip text */
	.tooltip .tooltiptext {
		visibility: hidden;
		width: 600px;
		background-color: #555;
		color: #fff;
		text-align: left;
		padding: 5px 0;
		border-radius: 6px;
		/* Position the tooltip text */
		position: absolute;
		z-index: 1;
		bottom: 125%;
		left: -100%;
		margin-left: -60px;
		/* Fade in tooltip */
		opacity: 0;
		transition: opacity 1s;
	}
	/* Tooltip arrow */
	.tooltip .tooltiptext::after {
		content: ;
		position: absolute;
		top: 100%;
		left: 50%;
		margin-left: -5px;
		border-width: 5px;
		border-style: solid;
		border-color: #555 transparent transparent transparent;
	}
	/* Show the tooltip text when you mouse over the tooltip container */
	.tooltip:hover .tooltiptext {
		visibility: visible;
		opacity: 1;
	}
</STYLE>
<h1>Profile Summary</h1>
<br>
<h3>Application: host</h3>
<h3>Created: 2020-01-19 17:21:40</h3>
<h3>Devices: xilinx_aws-vu9p-f1-04261818_dynamic_5_0-0</h3>
<h3>Msec: 1579454500124</h3>
<h3>Report name: Profile Summary</h3>
<h3>Target: Hardware Emulation</h3>
<h3>Tool version: 2019.1</h3>
<br>
<h2>OpenCL API Calls</h2>

<TABLE border="1">
<TR>
<TH>API Name</TH>
<TH>Number<br>Of Calls</TH>
<TH>Total<br>Time (ms)</TH>
<TH>Minimum<br>Time (ms)</TH>
<TH>Average<br>Time (ms)</TH>
<TH>Maximum<br>Time (ms)</TH>
</TR>
<TR>
<TD>clFinish</TD>
<TD>1</TD>
<TD>40872.900</TD>
<TD>40872.900</TD>
<TD>40872.900</TD>
<TD>40872.900</TD>
</TR>
<TR>
<TD>clCreateProgramWithBinary</TD>
<TD>1</TD>
<TD>10289.500</TD>
<TD>10289.500</TD>
<TD>10289.500</TD>
<TD>10289.500</TD>
</TR>
<TR>
<TD>clEnqueueTask</TD>
<TD>1</TD>
<TD>8.282</TD>
<TD>8.282</TD>
<TD>8.282</TD>
<TD>8.282</TD>
</TR>
<TR>
<TD>clReleaseProgram</TD>
<TD>1</TD>
<TD>2.217</TD>
<TD>2.217</TD>
<TD>2.217</TD>
<TD>2.217</TD>
</TR>
<TR>
<TD>clCreateKernel</TD>
<TD>1</TD>
<TD>0.947</TD>
<TD>0.947</TD>
<TD>0.947</TD>
<TD>0.947</TD>
</TR>
<TR>
<TD>clCreateBuffer</TD>
<TD>3</TD>
<TD>0.946</TD>
<TD>0.092</TD>
<TD>0.315</TD>
<TD>0.478</TD>
</TR>
<TR>
<TD>clEnqueueMigrateMemObjects</TD>
<TD>2</TD>
<TD>0.077</TD>
<TD>0.009</TD>
<TD>0.039</TD>
<TD>0.068</TD>
</TR>
<TR>
<TD>clGetExtensionFunctionAddress</TD>
<TD>2</TD>
<TD>0.017</TD>
<TD>0.003</TD>
<TD>0.009</TD>
<TD>0.014</TD>
</TR>
<TR>
<TD>clReleaseMemObject</TD>
<TD>9</TD>
<TD>0.014</TD>
<TD>0.001</TD>
<TD>0.002</TD>
<TD>0.003</TD>
</TR>
<TR>
<TD>clGetPlatformInfo</TD>
<TD>14</TD>
<TD>0.013</TD>
<TD>0.001</TD>
<TD>0.001</TD>
<TD>0.002</TD>
</TR>
<TR>
<TD>clReleaseKernel</TD>
<TD>1</TD>
<TD>0.013</TD>
<TD>0.013</TD>
<TD>0.013</TD>
<TD>0.013</TD>
</TR>
<TR>
<TD>clRetainMemObject</TD>
<TD>6</TD>
<TD>0.008</TD>
<TD>0.001</TD>
<TD>0.001</TD>
<TD>0.003</TD>
</TR>
<TR>
<TD>clSetKernelArg</TD>
<TD>4</TD>
<TD>0.008</TD>
<TD>0.001</TD>
<TD>0.002</TD>
<TD>0.004</TD>
</TR>
<TR>
<TD>clCreateCommandQueue</TD>
<TD>1</TD>
<TD>0.006</TD>
<TD>0.006</TD>
<TD>0.006</TD>
<TD>0.006</TD>
</TR>
<TR>
<TD>clGetDeviceIDs</TD>
<TD>2</TD>
<TD>0.005</TD>
<TD>0.001</TD>
<TD>0.002</TD>
<TD>0.004</TD>
</TR>
<TR>
<TD>clGetExtensionFunctionAddressForPlatform</TD>
<TD>2</TD>
<TD>0.005</TD>
<TD>0.001</TD>
<TD>0.002</TD>
<TD>0.004</TD>
</TR>
<TR>
<TD>clCreateContext</TD>
<TD>1</TD>
<TD>0.004</TD>
<TD>0.004</TD>
<TD>0.004</TD>
<TD>0.004</TD>
</TR>
<TR>
<TD>clReleaseCommandQueue</TD>
<TD>1</TD>
<TD>0.004</TD>
<TD>0.004</TD>
<TD>0.004</TD>
<TD>0.004</TD>
</TR>
<TR>
<TD>clReleaseDevice</TD>
<TD>2</TD>
<TD>0.002</TD>
<TD>0.001</TD>
<TD>0.001</TD>
<TD>0.001</TD>
</TR>
<TR>
<TD>clReleaseContext</TD>
<TD>1</TD>
<TD>0.002</TD>
<TD>0.002</TD>
<TD>0.002</TD>
<TD>0.002</TD>
</TR>
<TR>
<TD>clRetainDevice</TD>
<TD>2</TD>
<TD>0.002</TD>
<TD>0.001</TD>
<TD>0.001</TD>
<TD>0.001</TD>
</TR>
</TABLE>
<br>
<h2>Kernel Execution (includes estimated device times)</h2>

<TABLE border="1">
<TR>
<TH>Kernel</TH>
<TH>Number Of<br>Enqueues</TH>
<TH>Total<br>Time (ms)</TH>
<TH>Minimum<br>Time (ms)</TH>
<TH>Average<br>Time (ms)</TH>
<TH>Maximum<br>Time (ms)</TH>
</TR>
<TR>
<TD>vadd</TD>
<TD>1</TD>
<TD>0.225</TD>
<TD>0.225</TD>
<TD>0.225</TD>
<TD>0.225</TD>
</TR>
</TABLE>
<br>
<h2>Compute Unit Utilization (includes estimated device times)</h2>

<TABLE border="1">
<TR>
<TH>Device</TH>
<TH>Compute Unit</TH>
<TH>Kernel</TH>
<TH>Global<br>Work Size</TH>
<TH>Local<br>Work Size</TH>
<TH>Number<br>Of Calls</TH>
<TH>Dataflow<br>Execution</TH>
<TH>Max Parallel<br>Executions</TH>
<TH>Dataflow<br>Acceleration</TH>
<TH>Total<br>Time (ms)</TH>
<TH>Minimum<br>Time (ms)</TH>
<TH>Average<br>Time (ms)</TH>
<TH>Maximum<br>Time (ms)</TH>
<TH>Clock<br>Freq (MHz)</TH>
</TR>
<TR>
<TD>xilinx_aws-vu9p-f1-04261818_dynamic_5_0-0</TD>
<TD>vadd_1</TD>
<TD>vadd</TD>
<TD>1:1:1</TD>
<TD>1:1:1</TD>
<TD>1</TD>
<TD>No</TD>
<TD>0</TD>
<TD>1.000000x</TD>
<TD>0.223</TD>
<TD>0.223</TD>
<TD>0.223</TD>
<TD>0.223</TD>
<TD>300</TD>
</TR>
</TABLE>
<br>
<h2>Data Transfer: Host to Global Memory</h2>

<TABLE border="1">
<TR>
<TH>Context:Number<br>of Devices</TH>
<TH>Transfer Type</TH>
<TH>Number Of<br>Buffer Transfers</TH>
<TH>Transfer<br>Rate (MB/s)</TH>
<TH>Average Bandwidth<br>Utilization (%)</TH>
<TH>Average<br>Buffer Size (KB)</TH>
<TH>Total<br>Time (ms)</TH>
<TH>Average<br>Time (ms)</TH>
</TR>
<TR>
<TD>context0:1</TD>
<TD>READ</TD>
<TD>1</TD>
<TD>N/A</TD>
<TD>N/A</TD>
<TD>16.384</TD>
<TD>N/A</TD>
<TD>N/A</TD>
</TR>
<TR>
<TD>context0:1</TD>
<TD>WRITE</TD>
<TD>1</TD>
<TD>N/A</TD>
<TD>N/A</TD>
<TD>32.768</TD>
<TD>N/A</TD>
<TD>N/A</TD>
</TR>
</TABLE>
<br>
<h2>Data Transfer: Kernels to Global Memory</h2>

<TABLE border="1">
<TR>
<TH>Device</TH>
<TH>Compute Unit/<br>Port Name</TH>
<TH>Kernel Arguments</TH>
<TH>Memory Resources</TH>
<TH>Transfer Type</TH>
<TH>Number Of<br>Transfers</TH>
<TH>Transfer<br>Rate (MB/s)</TH>
<TH>Average Bandwidth<br>Utilization (%)</TH>
<TH>Average<br>Size (KB)</TH>
<TH>Average<br>Latency (ns)</TH>
</TR>
<TR>
<TD>xilinx_aws-vu9p-f1-04261818_dynamic_5_0-0</TD>
<TD>All</TD>
<TD>All</TD>
<TD>0</TD>
<TD>READ</TD>
<TD>16384</TD>
<TD>291.911</TD>
<TD>2.534</TD>
<TD>0.004</TD>
<TD>66.667</TD>
</TR>
<TR>
<TD>xilinx_aws-vu9p-f1-04261818_dynamic_5_0-0</TD>
<TD>All</TD>
<TD>All</TD>
<TD>0</TD>
<TD>WRITE</TD>
<TD>512</TD>
<TD>145.955</TD>
<TD>1.267</TD>
<TD>0.064</TD>
<TD>43.346</TD>
</TR>
</TABLE>
<br>
<h2>Top Data Transfer: Kernels to Global Memory</h2>

<TABLE border="1">
<TR>
<TH>Device</TH>
<TH>Compute Unit</TH>
<TH>Number Of<br>Transfers</TH>
<TH>Average Bytes<br>per Transfer</TH>
<TH>Transfer<br>Efficiency (%)</TH>
<TH>Total Data<br>Transfer (MB)</TH>
<TH>Total<br>Write (MB)</TH>
<TH>Total<br>Read (MB)</TH>
<TH>Total Transfer<br>Rate (MB/s)</TH>
</TR>
<TR>
<TD>xilinx_aws-vu9p-f1-04261818_dynamic_5_0-0</TD>
<TD>All</TD>
<TD>16896</TD>
<TD>5.818</TD>
<TD>0.142</TD>
<TD>0.098</TD>
<TD>0.033</TD>
<TD>0.066</TD>
<TD>437.866</TD>
</TR>
</TABLE>
<br>
<h2>Top Kernel Execution</h2>

<TABLE border="1">
<TR>
<TH>Kernel Instance<br>Address</TH>
<TH>Kernel</TH>
<TH>Context ID</TH>
<TH>Command<br>Queue ID</TH>
<TH>Device</TH>
<TH>Start<br>Time (ms)</TH>
<TH>Duration (ms)</TH>
<TH>Global<br>Work Size</TH>
<TH>Local<br>Work Size</TH>
</TR>
<TR>
<TD>0x1087450</TD>
<TD>vadd</TD>
<TD>0</TD>
<TD>0</TD>
<TD>xilinx_aws-vu9p-f1-04261818_dynamic_5_0-0</TD>
<TD>0.000</TD>
<TD>0.225</TD>
<TD>1:1:1</TD>
<TD>1:1:1</TD>
</TR>
</TABLE>
<br>
<h2>Top Memory Writes: Host to Global Memory</h2>

<TABLE border="1">
<TR>
<TH>Buffer Address</TH>
<TH>Context ID</TH>
<TH>Command<br>Queue ID</TH>
<TH>Start<br>Time (ms)</TH>
<TH>Duration (ms)</TH>
<TH>Buffer Size (KB)</TH>
<TH>Writing<br>Rate (MB/s)</TH>
</TR>
<TR>
<TD>0x0</TD>
<TD>0</TD>
<TD>0</TD>
<TD>10299.000</TD>
<TD>N/A</TD>
<TD>32.768</TD>
<TD>N/A</TD>
</TR>
</TABLE>
<br>
<h2>Top Memory Reads: Host to Global Memory</h2>

<TABLE border="1">
<TR>
<TH>Buffer Address</TH>
<TH>Context ID</TH>
<TH>Command<br>Queue ID</TH>
<TH>Start<br>Time (ms)</TH>
<TH>Duration (ms)</TH>
<TH>Buffer Size (KB)</TH>
<TH>Reading<br>Rate (MB/s)</TH>
</TR>
<TR>
<TD>0x8000</TD>
<TD>0</TD>
<TD>0</TD>
<TD>51165.500</TD>
<TD>N/A</TD>
<TD>16.384</TD>
<TD>N/A</TD>
</TR>
</TABLE>
<br>
<h2>Guidance (12 met, 8 warnings)</h2>

<TABLE border="1">
<TR>
<TH>Name</TH>
<TH>Threshold</TH>
<TH>Actual</TH>
<TH>Conclusion</TH>
<TH>Details</TH>
<TH>Resolution</TH>
</TR>
<TR>
<TD>Average Read Size (KB)</TD>
<TD>> 0.512</TD>
<TD>0.004</TD>
<TD>Not Met</TD>
<TD>Kernel read size of 0.004 KB on port All was low.</TD>
<TD>
  <a href=" " class="tooltip">Use burst transfers and packing into full memory data width.
    <span class="tooltiptext"><html>It is recommended to use burst read transfers of vector data types to increase your read transfer sizes. Burst transfers provide efficient requests, and vectors better utilize the memory data width.<br><br>For further details, in SDx navigate to &quot;Xilinx&#8594;Open SDx Example Store&#133;&quot; and install the <i>Wide Memory Read/Write</i> designs under &quot;SDAccel Examples&#8594;Getting Started Examples&#8594;Kernel to Global Memory Examples.&quot; These kernels use inferred bursts of a wide 512-bit interface.<br><br><a href="https://www.xilinx.com/cgi-bin/docs/rdoc?v=latest;d=ug1207-sdaccel-optimization-guide.pdf">SDAccel <br>Profiling and Optimization Guide</a></html></span>
  </a>
</TD>
</TR>
<TR>
<TD>Average Write Size (KB)</TD>
<TD>> 0.512</TD>
<TD>0.064</TD>
<TD>Not Met</TD>
<TD>Kernel write size of 0.064 KB on port All was low.</TD>
<TD>
  <a href=" " class="tooltip">Use burst transfers and packing into full memory data width.
    <span class="tooltiptext"><html>It is recommended to use burst write transfers of vector data types to increase your write transfer sizes. Burst transfers provide efficient requests, and vectors better utilize the memory data width.<br><br>For further details, in SDx navigate to &quot;Xilinx&#8594;Open SDx Example Store&#133;&quot; and install the <i>Wide Memory Read/Write</i> designs under &quot;SDAccel Examples&#8594;Getting Started Examples&#8594;Kernel to Global Memory Examples.&quot; These kernels use inferred bursts of a wide 512-bit interface.<br><br><a href="https://www.xilinx.com/cgi-bin/docs/rdoc?v=latest;d=ug1207-sdaccel-optimization-guide.pdf">SDAccel <br>Profiling and Optimization Guide</a></html></span>
  </a>
</TD>
</TR>
<TR>
<TD>Read Bandwidth (%)</TD>
<TD>> 5.000</TD>
<TD>2.534</TD>
<TD>Not Met</TD>
<TD>Kernel read utilization of 2.534% on port All was low.</TD>
<TD>
  <a href=" " class="tooltip">Improve kernel data path and/or memory read efficiency.
    <span class="tooltiptext"><html>There are a number of ways to increase this bandwidth utilization by improving the data paths of the kernels and/or the efficiency of the data transfers. Possible options include: loop unrolling, pipelining, vectorization, and maximizing memory port widths.<br><br><b><u>Not recommended:</b></u><pre><i/>
void vadd( __global int* a, __global int* b, __global int* c) {
  for (int i=0; i &lt 256; i++) {
    c[i] = a[i] + b[i];
  }
}</i></pre><b><u>Recommended:</b></u><pre><i/>
void vadd( __global <b>int16</b>* a, __global <b>int16</b>* b, __global <b>int16</b>* c) {
<b>  __attribute__((xcl_pipeline_loop))</b>
  for (int i=0; i &lt <b>256/16</b>; i++) {
    c[i] = a[i] + b[i];
  }
}</i></pre><a href="https://www.xilinx.com/cgi-bin/docs/rdoc?v=latest;d=ug1207-sdaccel-optimization-guide.pdf">SDAccel <br>Profiling and Optimization Guide</a></html></span>
  </a>
</TD>
</TR>
<TR>
<TD>Write Bandwidth (%)</TD>
<TD>> 5.000</TD>
<TD>1.267</TD>
<TD>Not Met</TD>
<TD>Kernel write utilization of 1.267% on port All was low.</TD>
<TD>
  <a href=" " class="tooltip">Improve kernel data path and/or memory write efficiency.
    <span class="tooltiptext"><html>There are a number of ways to increase this bandwidth utilization by improving the data paths of the kernels and/or the efficiency of the data transfers. Possible options include: loop unrolling, pipelining, vectorization, and maximizing memory port widths.<br><br><b><u>Not recommended:</b></u><pre><i/>
void vadd( __global int* a, __global int* b, __global int* c) {
  for (int i=0; i &lt 256; i++) {
    c[i] = a[i] + b[i];
  }
}</i></pre><b><u>Recommended:</b></u><pre><i/>
void vadd( __global <b>int16</b>* a, __global <b>int16</b>* b, __global <b>int16</b>* c) {
<b>  __attribute__((xcl_pipeline_loop))</b>
  for (int i=0; i &lt <b>256/16</b>; i++) {
    c[i] = a[i] + b[i];
  }
}</i></pre><a href="https://www.xilinx.com/cgi-bin/docs/rdoc?v=latest;d=ug1207-sdaccel-optimization-guide.pdf">SDAccel <br>Profiling and Optimization Guide</a></html></span>
  </a>
</TD>
</TR>
<TR>
<TD>Read Amount - Minimum (MB)</TD>
<TD>> 0.250</TD>
<TD>2.000</TD>
<TD>Met</TD>
<TD>Compute units on all devices used adequate data from host.</TD>
<TD></TD>
</TR>
<TR>
<TD>Read Amount - Maximum (MB)</TD>
<TD>< 2.000</TD>
<TD>2.000</TD>
<TD>Met</TD>
<TD>No data re-use issues were found between host and compute units.</TD>
<TD></TD>
</TR>
<TR>
<TD>Port Data Width</TD>
<TD>= 512</TD>
<TD>32</TD>
<TD>Not Met</TD>
<TD>Port vadd_1/m_axi_gmem has a data width of 32.</TD>
<TD>
  <a href=" " class="tooltip">Utilize the entire memory data width.
    <span class="tooltiptext"><html>The width of data paths between kernels and the memory controller can be configured by the SDAccel compiler as 32, 64, 128, 256, or 512 bits depending on kernel argument types. For applications that require maximum data bandwidth between the kernel and DDR memory, it is recommended that global pointers are defined explicitly as 512-bit data types.<br><br>See Chapter 4 of <a href="https://www.xilinx.com/cgi-bin/docs/rdoc?v=latest;d=ug1207-sdaccel-optimization-guide.pdf">SDAccel <br>Profiling and Optimization Guide</a></html></span>
  </a>
</TD>
</TR>
<TR>
<TD>Memory Connections</TD>
<TD>> 0</TD>
<TD>1</TD>
<TD>Met</TD>
<TD>Memory DDR[0] was used.</TD>
<TD></TD>
</TR>
<TR>
<TD>PLRAM Usage</TD>
<TD>> 0</TD>
<TD>0</TD>
<TD>Not Met</TD>
<TD>PLRAMs were used by 0 port(s).</TD>
<TD>
  <a href=" " class="tooltip">Utilize PLRAMs to maximize performance.
    <span class="tooltiptext"><html>PLRAMs can increase your system performance by providing low-latency, high-bandwidth access to your data. To take advantage of PLRAMs, assign CL memory buffers to PLRAMs in the host code and specify corresponding port mapping using the --sp xocc linker option:<pre><i/>xocc -l --sp &lt;compute_unit_name&gt;.&lt;kernel_interface_name&gt;:PLRAM[0:3]</i></pre>For more information, see examples in the Kernel To Global Memory category from the Xilinx On-boarding Example GitHub.</html></span>
  </a>
</TD>
</TR>
<TR>
<TD>Memory Read Bandwidth (%)</TD>
<TD>> 5.000</TD>
<TD>2.534</TD>
<TD>Not Met</TD>
<TD>Memory 0 read utilization of 2.534% on device xilinx_aws-vu9p-f1-04261818_dynamic_5_0-0 was low.</TD>
<TD>
  <a href=" " class="tooltip">Improve kernel memory read efficiency to memories.
    <span class="tooltiptext"><html>Devices with multiple DDR banks can provide very high bandwidth to global memory. It is recommended to utilize more of the available read bandwidth to this DDR bank if it suits your application.<br><br>See Chapter 4 of <a href="https://www.xilinx.com/cgi-bin/docs/rdoc?v=latest;d=ug1207-sdaccel-optimization-guide.pdf">SDAccel <br>Profiling and Optimization Guide</a></html></span>
  </a>
</TD>
</TR>
<TR>
<TD>Memory Write Bandwidth (%)</TD>
<TD>> 5.000</TD>
<TD>1.267</TD>
<TD>Not Met</TD>
<TD>Memory 0 write utilization of 1.267% on device xilinx_aws-vu9p-f1-04261818_dynamic_5_0-0 was low.</TD>
<TD>
  <a href=" " class="tooltip">Improve kernel memory write efficiency to memories.
    <span class="tooltiptext"><html>Devices with multiple DDR banks can provide very high bandwidth to global memory. It is recommended to utilize more of the available write bandwidth to this DDR bank if it suits your application.<br><br>See Chapter 4 of <a href="https://www.xilinx.com/cgi-bin/docs/rdoc?v=latest;d=ug1207-sdaccel-optimization-guide.pdf">SDAccel <br>Profiling and Optimization Guide</a></html></span>
  </a>
</TD>
</TR>
<TR>
<TD>Migrate Memory API Calls</TD>
<TD>> 0</TD>
<TD>2</TD>
<TD>Met</TD>
<TD>Migrate Memory APIs (e.g., clEnqueueMigrateMemObjects) were used.</TD>
<TD></TD>
</TR>
<TR>
<TD>Average Read Size (KB)</TD>
<TD>> 4.096</TD>
<TD>16.384</TD>
<TD>Met</TD>
<TD>Host read transfers were efficient from off-chip global memory.</TD>
<TD></TD>
</TR>
<TR>
<TD>Average Write Size (KB)</TD>
<TD>> 4.096</TD>
<TD>32.768</TD>
<TD>Met</TD>
<TD>Host write transfers were efficient to off-chip global memory.</TD>
<TD></TD>
</TR>
<TR>
<TD>Compute Unit Calls - Minimum</TD>
<TD>> 0</TD>
<TD>1</TD>
<TD>Met</TD>
<TD>Compute unit vadd_1 on device xilinx_aws-vu9p-f1-04261818_dynamic_5_0-0 was used.</TD>
<TD></TD>
</TR>
<TR>
<TD>Compute Unit Utilization (%)</TD>
<TD>> 20.000</TD>
<TD>99.362</TD>
<TD>Met</TD>
<TD>Compute unit vadd_1 had sufficient utilization.</TD>
<TD></TD>
</TR>
<TR>
<TD>Compute Unit Calls - Maximum</TD>
<TD>< 16</TD>
<TD>1</TD>
<TD>Met</TD>
<TD>Kernel vadd was used an adequate amount.</TD>
<TD></TD>
</TR>
<TR>
<TD>Kernel Utilization (%)</TD>
<TD>= 100.000</TD>
<TD>100.000</TD>
<TD>Met</TD>
<TD>Kernel vadd utilized correct amount of workgroups.</TD>
<TD></TD>
</TR>
<TR>
<TD>Device Utilization (ms)</TD>
<TD>> 0</TD>
<TD>0.225</TD>
<TD>Met</TD>
<TD>Device xilinx_aws-vu9p-f1-04261818_dynamic_5_0-0 was used.</TD>
<TD></TD>
</TR>
<TR>
<TD>Objects Released</TD>
<TD>true</TD>
<TD>true</TD>
<TD>Met</TD>
<TD>OpenCL objects were released by the host code.</TD>
<TD></TD>
</TR>
</TABLE>
